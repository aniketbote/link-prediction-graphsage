{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-QnrfgWkWYD-"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "os.environ['TORCH'] = torch.__version__\n",
        "print(torch.__version__)\n",
        "\n",
        "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eONbbCiLlKE5"
      },
      "outputs": [],
      "source": [
        "!pip install ogb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BBzUNK7blIcS"
      },
      "outputs": [],
      "source": [
        "from ogb.linkproppred import PygLinkPropPredDataset, Evaluator\n",
        "import torch_geometric.transforms as T\n",
        "from torch_geometric.nn import SAGEConv\n",
        "from torch_geometric.utils import negative_sampling, add_self_loops\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XgHKWvRBjkE2"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-CUX92-glAPI"
      },
      "outputs": [],
      "source": [
        "dataset = PygLinkPropPredDataset(name=\"ogbl-ddi\", root=\"dataset\")\n",
        "data = dataset[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3imUvz13l2HM"
      },
      "outputs": [],
      "source": [
        "# Forming edge_index\n",
        "data = T.ToSparseTensor()(data)\n",
        "row, col, _ = data.adj_t.coo()\n",
        "data.edge_index = torch.stack([col, row], dim=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OOFKTpObmayG"
      },
      "outputs": [],
      "source": [
        "# creating train test split\n",
        "split_edge = dataset.get_edge_split()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KfT725CbaJRZ"
      },
      "outputs": [],
      "source": [
        "data = data.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fYxP8nZx2ID_"
      },
      "outputs": [],
      "source": [
        "class GNNStack(torch.nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, num_layers, dropout):\n",
        "        super(GNNStack, self).__init__()\n",
        "        conv_model = SAGEConv\n",
        "\n",
        "        self.convs = torch.nn.ModuleList()\n",
        "        self.convs.append(conv_model(input_dim, hidden_dim))\n",
        "        self.dropout = dropout\n",
        "        self.num_layers = num_layers\n",
        "  \n",
        "        for l in range(self.num_layers - 1):\n",
        "            self.convs.append(conv_model(hidden_dim, hidden_dim))\n",
        "\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        for i in range(self.num_layers-1):\n",
        "            x = self.convs[i](x, edge_index)\n",
        "            x = F.relu(x)\n",
        "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "\n",
        "        x = self.convs[-1](x, edge_index)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "93lB2BJw3YGd"
      },
      "outputs": [],
      "source": [
        "# GNNStack(512,512,2,0.3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IyllWEOj4lXp"
      },
      "outputs": [],
      "source": [
        "class LinkPredictor(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers,\n",
        "                 dropout):\n",
        "        super(LinkPredictor, self).__init__()\n",
        "\n",
        "        # Create linear layers\n",
        "        self.lins = torch.nn.ModuleList()\n",
        "        self.lins.append(torch.nn.Linear(in_channels, hidden_channels))\n",
        "        for _ in range(num_layers - 2):\n",
        "            self.lins.append(torch.nn.Linear(hidden_channels, hidden_channels))\n",
        "        self.lins.append(torch.nn.Linear(hidden_channels, out_channels))\n",
        "\n",
        "        self.dropout = dropout\n",
        "\n",
        "  \n",
        "    def forward(self, x_i, x_j):\n",
        "        # x_i and x_j are both of shape (E, D)\n",
        "        x = x_i * x_j\n",
        "        for lin in self.lins[:-1]:\n",
        "            x = lin(x)\n",
        "            x = F.relu(x)\n",
        "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "        x = self.lins[-1](x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yptNB88m5ItT"
      },
      "outputs": [],
      "source": [
        "# LinkPredictor(512, 512, 1, 2, 0.3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5I5mDvOWEJkI"
      },
      "outputs": [],
      "source": [
        "def get_pos_neg_edges(split, split_edge, edge_index = None, num_nodes = None, num_neg = None):\n",
        "  pos_edge = split_edge[split]['edge']\n",
        "  new_edge_index, _ = add_self_loops(edge_index)\n",
        "  if split == 'train':\n",
        "    neg_edge = negative_sampling(new_edge_index, num_nodes=num_nodes, num_neg_samples=pos_edge.size(0) * num_neg, method='sparse')\n",
        "    assert neg_edge.size(1) == pos_edge.size(0) * num_neg\n",
        "    neg_src = neg_edge[0]\n",
        "    neg_dst = neg_edge[1]\n",
        "    neg_edge = torch.reshape(torch.stack(\n",
        "        (neg_src, neg_dst), dim=-1), (-1, num_neg, 2))\n",
        "  else:\n",
        "    neg_edge = split_edge[split]['edge_neg']\n",
        "  \n",
        "  \n",
        "  return pos_edge, neg_edge\n",
        "\n",
        "def evaluate_hits(evaluator, pos_val_pred, neg_val_pred,\n",
        "                  pos_test_pred, neg_test_pred):\n",
        "    results = {}\n",
        "    for K in [20, 50, 100]:\n",
        "        evaluator.K = K\n",
        "        valid_hits = evaluator.eval({\n",
        "            'y_pred_pos': pos_val_pred,\n",
        "            'y_pred_neg': neg_val_pred,\n",
        "        })[f'hits@{K}']\n",
        "        test_hits = evaluator.eval({\n",
        "            'y_pred_pos': pos_test_pred,\n",
        "            'y_pred_neg': neg_test_pred,\n",
        "        })[f'hits@{K}']\n",
        "\n",
        "        results[f'Hits@{K}'] = (valid_hits, test_hits)\n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c7sa6rujnRab"
      },
      "outputs": [],
      "source": [
        "class Model():\n",
        "  def __init__(self, num_nodes, emb_dim, device, num_layers, dropout, lr) -> None:\n",
        "    self.num_nodes = num_nodes\n",
        "    self.device = device\n",
        "    self.emb = torch.nn.Embedding(num_nodes, emb_dim).to(device)\n",
        "    self.encoder = GNNStack(emb_dim,emb_dim,num_layers,dropout).to(device)\n",
        "    self.predictor = LinkPredictor(emb_dim, emb_dim, 1, num_layers, dropout).to(device)\n",
        "    self.optimizer = torch.optim.Adam(list(self.emb.parameters()) + list(self.encoder.parameters()) + list(self.predictor.parameters()),lr=lr)\n",
        "    self.para_list = list(self.encoder.parameters()) + list(self.predictor.parameters()) + list(self.emb.parameters())\n",
        "  \n",
        "  def auc_loss(self, pos_out, neg_out, num_neg):\n",
        "    pos_out = torch.reshape(pos_out, (-1, 1))\n",
        "    neg_out = torch.reshape(neg_out, (-1, num_neg))\n",
        "    return torch.square(1 - (pos_out - neg_out)).sum()\n",
        "\n",
        "  def train(self, data, split_edge, batch_size, num_neg):\n",
        "    self.encoder.train()\n",
        "    self.predictor.train()\n",
        "\n",
        "    pos_train_edge, neg_train_edge = get_pos_neg_edges('train', split_edge,\n",
        "                                                           edge_index=data.edge_index,\n",
        "                                                           num_nodes=self.num_nodes,\n",
        "                                                           num_neg = num_neg)\n",
        "    \n",
        "    pos_train_edge, neg_train_edge = pos_train_edge.to(self.device), neg_train_edge.to(self.device)\n",
        "\n",
        "    total_loss = total_examples = 0\n",
        "    for perm in DataLoader(range(pos_train_edge.size(0)), batch_size, shuffle=True):\n",
        "      self.optimizer.zero_grad()\n",
        "\n",
        "      input_feat = self.emb.weight\n",
        "      h = self.encoder(input_feat, data.adj_t)\n",
        "      pos_edge = pos_train_edge[perm].t()\n",
        "  \n",
        "      neg_edge = torch.reshape(neg_train_edge[perm], (-1, 2)).t()\n",
        "\n",
        "      pos_out = self.predictor(h[pos_edge[0]], h[pos_edge[1]])\n",
        "      neg_out = self.predictor(h[neg_edge[0]], h[neg_edge[1]])\n",
        "\n",
        "      loss = self.auc_loss(pos_out, neg_out, num_neg)\n",
        "      loss.backward()\n",
        "\n",
        "      torch.nn.utils.clip_grad_norm_(self.encoder.parameters(), 2)\n",
        "      torch.nn.utils.clip_grad_norm_(self.predictor.parameters(), 2)\n",
        "\n",
        "      self.optimizer.step()\n",
        "\n",
        "      num_examples = pos_out.size(0)\n",
        "      total_loss += loss.item() * num_examples\n",
        "      total_examples += num_examples\n",
        "\n",
        "    return total_loss / total_examples\n",
        "\n",
        "  @torch.no_grad()\n",
        "  def batch_predict(self, h, edges, batch_size):\n",
        "    self.predictor.eval()\n",
        "    preds = []\n",
        "    for perm in DataLoader(range(edges.size(0)), batch_size):\n",
        "        edge = edges[perm].t()\n",
        "        preds += [self.predictor(h[edge[0]], h[edge[1]]).squeeze().cpu()]\n",
        "    pred = torch.cat(preds, dim=0)\n",
        "    return pred\n",
        "                                                    \n",
        "\n",
        "\n",
        "  @torch.no_grad()\n",
        "  def test(self, data, split_edge, batch_size, evaluator):\n",
        "    self.encoder.eval()\n",
        "    self.predictor.eval()\n",
        "\n",
        "    input_feat = self.emb.weight\n",
        "    h = self.encoder(input_feat, data.adj_t)\n",
        "    # The default index of unseen nodes is -1,\n",
        "    # hidden representations of unseen nodes is the average of all seen node representations\n",
        "    # mean_h = torch.mean(h, dim=0, keepdim=True)\n",
        "    # h = torch.cat([h, mean_h], dim=0)\n",
        "\n",
        "    pos_valid_edge, neg_valid_edge = get_pos_neg_edges('valid', split_edge, edge_index=data.edge_index,\n",
        "                                                           num_nodes=self.num_nodes)\n",
        "                                                           \n",
        "    pos_test_edge, neg_test_edge = get_pos_neg_edges('test', split_edge, edge_index=data.edge_index,\n",
        "                                                           num_nodes=self.num_nodes)\n",
        "    pos_valid_edge, neg_valid_edge = pos_valid_edge.to(self.device), neg_valid_edge.to(self.device)\n",
        "    pos_test_edge, neg_test_edge = pos_test_edge.to(self.device), neg_test_edge.to(self.device)\n",
        "\n",
        "    pos_valid_pred = self.batch_predict(h, pos_valid_edge, batch_size)\n",
        "    neg_valid_pred = self.batch_predict(h, neg_valid_edge, batch_size)\n",
        "\n",
        "    h = self.encoder(input_feat, data.adj_t)\n",
        "    # mean_h = torch.mean(h, dim=0, keepdim=True)\n",
        "    # h = torch.cat([h, mean_h], dim=0)\n",
        "\n",
        "    pos_test_pred = self.batch_predict(h, pos_test_edge, batch_size)\n",
        "    neg_test_pred = self.batch_predict(h, neg_test_edge, batch_size)\n",
        "\n",
        "    results = evaluate_hits(\n",
        "            evaluator,\n",
        "            pos_valid_pred,\n",
        "            neg_valid_pred,\n",
        "            pos_test_pred,\n",
        "            neg_test_pred)\n",
        "\n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vHJ6oCgR3--a"
      },
      "outputs": [],
      "source": [
        "model = Model(data.num_nodes, 512, device, 2, 0.3, 1e-3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O7uEIt1mfDOF"
      },
      "outputs": [],
      "source": [
        "#3_497_473\n",
        "total_params = sum(p.numel() for param in model.para_list for p in param)\n",
        "total_params_print = f'Total number of model parameters is {total_params}'\n",
        "total_params_print"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tgw3oB9VFC7G"
      },
      "outputs": [],
      "source": [
        "evaluator = Evaluator(name='ogbl-ddi')\n",
        "print(evaluator.expected_input_format)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IfD67t07Smi5"
      },
      "outputs": [],
      "source": [
        "epochs = 1000\n",
        "batch_size = 65536\n",
        "num_neg = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sio2AqaUFxvF"
      },
      "outputs": [],
      "source": [
        "train_loss = []\n",
        "val_hits = []\n",
        "test_hits = []\n",
        "\n",
        "for epoch in range(1, 1 + epochs):\n",
        "  loss = model.train(data, split_edge,batch_size=batch_size,num_neg=num_neg)\n",
        "  print(f\"Epoch {epoch}: loss: {round(loss, 5)}\")\n",
        "  train_loss.append(loss)\n",
        "\n",
        "  if epoch % 10 == 0:\n",
        "      results = model.test(data, split_edge,\n",
        "                            batch_size=batch_size,\n",
        "                            evaluator=evaluator)\n",
        "      val_hits.append(results['Hits@20'][0])\n",
        "      test_hits.append(results['Hits@20'][1])\n",
        "      print(results)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-BRUejPAGF5X"
      },
      "outputs": [],
      "source": [
        "plt.title('Link Prediction on OGB-ddi using GraphSAGE GNN - Loss Curve')\n",
        "plt.plot(train_loss,label=\"training loss\")\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.savefig('loss-curve-ddi.png', dpi = 300)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o9QJsEy708Vv"
      },
      "outputs": [],
      "source": [
        "plt.title('Link Prediction on OGB-ddi using GraphSAGE GNN - Hits@20')\n",
        "plt.plot(np.arange(9,epochs,10),val_hits,label=\"Hits@20 on validation\")\n",
        "plt.plot(np.arange(9,epochs,10),test_hits,label=\"Hits@20 on test\")\n",
        "plt.xlabel('Epochs')\n",
        "plt.xlabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.savefig('Hits@20-curve-ddi.png', dpi = 300)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MY6DaMtjLMI6"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
